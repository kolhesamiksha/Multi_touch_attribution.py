{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc62824c",
   "metadata": {},
   "source": [
    "## Create and Populate Ad Spend Table\n",
    "\n",
    "- Create ad spend table\n",
    "- Create widget for specifying the ad spend for a given campaign\n",
    "- Populate ad spend table with synthetic spend data\n",
    "- View campaign ad spend details\n",
    "- Explode struct into multiple rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a96c513b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp\n",
    "from pyspark.sql.types import *\n",
    "import time\n",
    "import pyspark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, HiveContext\n",
    "from minio import Minio\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('demo').config(\"hive.metastore.uris\", \"thrift://localhost:9083\", conf=SparkConf()).enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17946be2",
   "metadata": {},
   "source": [
    "- **View campaign ad spend details**\n",
    "\n",
    "The channel spend data currently exists as an array. We will explode these values into separate columns in the next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28fdfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS user_ad_spend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f4af7bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nextraneous input ',' expecting {'ADD', 'AFTER', 'ALL', 'ALTER', 'ANALYZE', 'AND', 'ANTI', 'ANY', 'ARCHIVE', 'ARRAY', 'AS', 'ASC', 'AT', 'AUTHORIZATION', 'BETWEEN', 'BOTH', 'BUCKET', 'BUCKETS', 'BY', 'CACHE', 'CASCADE', 'CASE', 'CAST', 'CHANGE', 'CHECK', 'CLEAR', 'CLUSTER', 'CLUSTERED', 'CODEGEN', 'COLLATE', 'COLLECTION', 'COLUMN', 'COLUMNS', 'COMMENT', 'COMMIT', 'COMPACT', 'COMPACTIONS', 'COMPUTE', 'CONCATENATE', 'CONSTRAINT', 'COST', 'CREATE', 'CROSS', 'CUBE', 'CURRENT', 'CURRENT_DATE', 'CURRENT_TIME', 'CURRENT_TIMESTAMP', 'CURRENT_USER', 'DAY', 'DATA', 'DATABASE', DATABASES, 'DBPROPERTIES', 'DEFINED', 'DELETE', 'DELIMITED', 'DESC', 'DESCRIBE', 'DFS', 'DIRECTORIES', 'DIRECTORY', 'DISTINCT', 'DISTRIBUTE', 'DIV', 'DROP', 'ELSE', 'END', 'ESCAPE', 'ESCAPED', 'EXCEPT', 'EXCHANGE', 'EXISTS', 'EXPLAIN', 'EXPORT', 'EXTENDED', 'EXTERNAL', 'EXTRACT', 'FALSE', 'FETCH', 'FIELDS', 'FILTER', 'FILEFORMAT', 'FIRST', 'FOLLOWING', 'FOR', 'FOREIGN', 'FORMAT', 'FORMATTED', 'FROM', 'FULL', 'FUNCTION', 'FUNCTIONS', 'GLOBAL', 'GRANT', 'GROUP', 'GROUPING', 'HAVING', 'HOUR', 'IF', 'IGNORE', 'IMPORT', 'IN', 'INDEX', 'INDEXES', 'INNER', 'INPATH', 'INPUTFORMAT', 'INSERT', 'INTERSECT', 'INTERVAL', 'INTO', 'IS', 'ITEMS', 'JOIN', 'KEYS', 'LAST', 'LATERAL', 'LAZY', 'LEADING', 'LEFT', 'LIKE', 'LIMIT', 'LINES', 'LIST', 'LOAD', 'LOCAL', 'LOCATION', 'LOCK', 'LOCKS', 'LOGICAL', 'MACRO', 'MAP', 'MATCHED', 'MERGE', 'MINUTE', 'MONTH', 'MSCK', 'NAMESPACE', 'NAMESPACES', 'NATURAL', 'NO', NOT, 'NULL', 'NULLS', 'OF', 'ON', 'ONLY', 'OPTION', 'OPTIONS', 'OR', 'ORDER', 'OUT', 'OUTER', 'OUTPUTFORMAT', 'OVER', 'OVERLAPS', 'OVERLAY', 'OVERWRITE', 'PARTITION', 'PARTITIONED', 'PARTITIONS', 'PERCENT', 'PIVOT', 'PLACING', 'POSITION', 'PRECEDING', 'PRIMARY', 'PRINCIPALS', 'PROPERTIES', 'PURGE', 'QUERY', 'RANGE', 'RECORDREADER', 'RECORDWRITER', 'RECOVER', 'REDUCE', 'REFERENCES', 'REFRESH', 'RENAME', 'REPAIR', 'REPLACE', 'RESET', 'RESPECT', 'RESTRICT', 'REVOKE', 'RIGHT', RLIKE, 'ROLE', 'ROLES', 'ROLLBACK', 'ROLLUP', 'ROW', 'ROWS', 'SECOND', 'SCHEMA', 'SELECT', 'SEMI', 'SEPARATED', 'SERDE', 'SERDEPROPERTIES', 'SESSION_USER', 'SET', 'MINUS', 'SETS', 'SHOW', 'SKEWED', 'SOME', 'SORT', 'SORTED', 'START', 'STATISTICS', 'STORED', 'STRATIFY', 'STRUCT', 'SUBSTR', 'SUBSTRING', 'SYNC', 'TABLE', 'TABLES', 'TABLESAMPLE', 'TBLPROPERTIES', TEMPORARY, 'TERMINATED', 'THEN', 'TIME', 'TO', 'TOUCH', 'TRAILING', 'TRANSACTION', 'TRANSACTIONS', 'TRANSFORM', 'TRIM', 'TRUE', 'TRUNCATE', 'TRY_CAST', 'TYPE', 'UNARCHIVE', 'UNBOUNDED', 'UNCACHE', 'UNION', 'UNIQUE', 'UNKNOWN', 'UNLOCK', 'UNSET', 'UPDATE', 'USE', 'USER', 'USING', 'VALUES', 'VIEW', 'VIEWS', 'WHEN', 'WHERE', 'WINDOW', 'WITH', 'YEAR', 'ZONE', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 11)\n\n== SQL ==\ncampaign_id, total_spend_in_dollars, channel_spend, campaign_start_date\n-----------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m3d65f7e92e81480cac52a20dfdf64d5b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m     \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSearch Engine Marketing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmail\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSocial Network\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAffiliates\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGoogle Display Network\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m     \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2020\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcampaign_id, total_spend_in_dollars, channel_spend, campaign_start_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/session.py:661\u001b[0m, in \u001b[0;36mSparkSession.createDataFrame\u001b[0;34m(self, data, schema, samplingRatio, verifySchema)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata is already a DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 661\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[43m_parse_datatype_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[1;32m    663\u001b[0m     \u001b[38;5;66;03m# Must re-encode any unicode strings to be consistent with StructField names\u001b[39;00m\n\u001b[1;32m    664\u001b[0m     schema \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mencode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m schema]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/types.py:843\u001b[0m, in \u001b[0;36m_parse_datatype_string\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m from_ddl_datatype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstruct<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m s\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 843\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/types.py:833\u001b[0m, in \u001b[0;36m_parse_datatype_string\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    828\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_datatype_json_string(\n\u001b[1;32m    829\u001b[0m         sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39morg\u001b[38;5;241m.\u001b[39mapache\u001b[38;5;241m.\u001b[39mspark\u001b[38;5;241m.\u001b[39msql\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mpython\u001b[38;5;241m.\u001b[39mPythonSQLUtils\u001b[38;5;241m.\u001b[39mparseDataType(type_str)\u001b[38;5;241m.\u001b[39mjson())\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    832\u001b[0m     \u001b[38;5;66;03m# DDL format, \"fieldname datatype, fieldname datatype\".\u001b[39;00m\n\u001b[0;32m--> 833\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_ddl_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    835\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    836\u001b[0m         \u001b[38;5;66;03m# For backwards compatibility, \"integer\", \"struct<fieldname: datatype>\" and etc.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/types.py:825\u001b[0m, in \u001b[0;36m_parse_datatype_string.<locals>.from_ddl_schema\u001b[0;34m(type_str)\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_ddl_schema\u001b[39m(type_str):\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_datatype_json_string(\n\u001b[0;32m--> 825\u001b[0m         \u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromDDL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_str\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mParseException\u001b[0m: \nextraneous input ',' expecting {'ADD', 'AFTER', 'ALL', 'ALTER', 'ANALYZE', 'AND', 'ANTI', 'ANY', 'ARCHIVE', 'ARRAY', 'AS', 'ASC', 'AT', 'AUTHORIZATION', 'BETWEEN', 'BOTH', 'BUCKET', 'BUCKETS', 'BY', 'CACHE', 'CASCADE', 'CASE', 'CAST', 'CHANGE', 'CHECK', 'CLEAR', 'CLUSTER', 'CLUSTERED', 'CODEGEN', 'COLLATE', 'COLLECTION', 'COLUMN', 'COLUMNS', 'COMMENT', 'COMMIT', 'COMPACT', 'COMPACTIONS', 'COMPUTE', 'CONCATENATE', 'CONSTRAINT', 'COST', 'CREATE', 'CROSS', 'CUBE', 'CURRENT', 'CURRENT_DATE', 'CURRENT_TIME', 'CURRENT_TIMESTAMP', 'CURRENT_USER', 'DAY', 'DATA', 'DATABASE', DATABASES, 'DBPROPERTIES', 'DEFINED', 'DELETE', 'DELIMITED', 'DESC', 'DESCRIBE', 'DFS', 'DIRECTORIES', 'DIRECTORY', 'DISTINCT', 'DISTRIBUTE', 'DIV', 'DROP', 'ELSE', 'END', 'ESCAPE', 'ESCAPED', 'EXCEPT', 'EXCHANGE', 'EXISTS', 'EXPLAIN', 'EXPORT', 'EXTENDED', 'EXTERNAL', 'EXTRACT', 'FALSE', 'FETCH', 'FIELDS', 'FILTER', 'FILEFORMAT', 'FIRST', 'FOLLOWING', 'FOR', 'FOREIGN', 'FORMAT', 'FORMATTED', 'FROM', 'FULL', 'FUNCTION', 'FUNCTIONS', 'GLOBAL', 'GRANT', 'GROUP', 'GROUPING', 'HAVING', 'HOUR', 'IF', 'IGNORE', 'IMPORT', 'IN', 'INDEX', 'INDEXES', 'INNER', 'INPATH', 'INPUTFORMAT', 'INSERT', 'INTERSECT', 'INTERVAL', 'INTO', 'IS', 'ITEMS', 'JOIN', 'KEYS', 'LAST', 'LATERAL', 'LAZY', 'LEADING', 'LEFT', 'LIKE', 'LIMIT', 'LINES', 'LIST', 'LOAD', 'LOCAL', 'LOCATION', 'LOCK', 'LOCKS', 'LOGICAL', 'MACRO', 'MAP', 'MATCHED', 'MERGE', 'MINUTE', 'MONTH', 'MSCK', 'NAMESPACE', 'NAMESPACES', 'NATURAL', 'NO', NOT, 'NULL', 'NULLS', 'OF', 'ON', 'ONLY', 'OPTION', 'OPTIONS', 'OR', 'ORDER', 'OUT', 'OUTER', 'OUTPUTFORMAT', 'OVER', 'OVERLAPS', 'OVERLAY', 'OVERWRITE', 'PARTITION', 'PARTITIONED', 'PARTITIONS', 'PERCENT', 'PIVOT', 'PLACING', 'POSITION', 'PRECEDING', 'PRIMARY', 'PRINCIPALS', 'PROPERTIES', 'PURGE', 'QUERY', 'RANGE', 'RECORDREADER', 'RECORDWRITER', 'RECOVER', 'REDUCE', 'REFERENCES', 'REFRESH', 'RENAME', 'REPAIR', 'REPLACE', 'RESET', 'RESPECT', 'RESTRICT', 'REVOKE', 'RIGHT', RLIKE, 'ROLE', 'ROLES', 'ROLLBACK', 'ROLLUP', 'ROW', 'ROWS', 'SECOND', 'SCHEMA', 'SELECT', 'SEMI', 'SEPARATED', 'SERDE', 'SERDEPROPERTIES', 'SESSION_USER', 'SET', 'MINUS', 'SETS', 'SHOW', 'SKEWED', 'SOME', 'SORT', 'SORTED', 'START', 'STATISTICS', 'STORED', 'STRATIFY', 'STRUCT', 'SUBSTR', 'SUBSTRING', 'SYNC', 'TABLE', 'TABLES', 'TABLESAMPLE', 'TBLPROPERTIES', TEMPORARY, 'TERMINATED', 'THEN', 'TIME', 'TO', 'TOUCH', 'TRAILING', 'TRANSACTION', 'TRANSACTIONS', 'TRANSFORM', 'TRIM', 'TRUE', 'TRUNCATE', 'TRY_CAST', 'TYPE', 'UNARCHIVE', 'UNBOUNDED', 'UNCACHE', 'UNION', 'UNIQUE', 'UNKNOWN', 'UNLOCK', 'UNSET', 'UPDATE', 'USE', 'USER', 'USING', 'VALUES', 'VIEW', 'VIEWS', 'WHEN', 'WHERE', 'WINDOW', 'WITH', 'YEAR', 'ZONE', IDENTIFIER, BACKQUOTED_IDENTIFIER}(line 1, pos 11)\n\n== SQL ==\ncampaign_id, total_spend_in_dollars, channel_spend, campaign_start_date\n-----------^^^\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([\n",
    "    (\"3d65f7e92e81480cac52a20dfdf64d5b\",\n",
    "     1000,\n",
    "    {'Search Engine Marketing':.2,'Email':.2,\n",
    "    \"Social Network\": 0.2,\n",
    "    \"Affiliates\": 0.2,\n",
    "    \"Google Display Network\": 0.2},\n",
    "     to_timestamp(2020, 5, 17, 0, 0, 0))],schema='campaign_id STRING, total_spend_in_dollars FLOAT, channel_spend dict, campaign_start_date TIMESTAMP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93f86b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option(\"header\",True) \\\n",
    "          .csv(\"gold_ad_spend.csv\") \\\n",
    "          .createOrReplaceTempView(\"gold_ad_spend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "77eef32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+----------------------+--------------------+-------------------+\n",
      "|_c0|         campaign_id|total_spend_in_dollars|       channel_spend|campaign_start_date|\n",
      "+---+--------------------+----------------------+--------------------+-------------------+\n",
      "|  0|3d65f7e92e81480ca...|                  1000|{'Search Engine M...|         'Email':.2|\n",
      "+---+--------------------+----------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from gold_ad_spend\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09d012",
   "metadata": {},
   "source": [
    "Explode struct into multiple rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8064e107",
   "metadata": {},
   "source": [
    "### View Campaign Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ab6c50",
   "metadata": {},
   "source": [
    "In this section, we will create the following charts:\n",
    "\n",
    "- Base conversion rate\n",
    "- Conversions by date\n",
    "- Attribution by model type\n",
    "- Cost per acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d09198",
   "metadata": {},
   "source": [
    "### Base conversion rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579e36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TABLE base_conversion_rate\n",
    "USING DELTA AS\n",
    "SELECT count(*) as count,\n",
    "  CASE \n",
    "    WHEN conversion == 0 \n",
    "    THEN 'Impression'\n",
    "    ELSE 'Conversion'\n",
    "  END AS interaction_type\n",
    "FROM\n",
    "  gold_user_journey\n",
    "GROUP BY\n",
    "  conversion;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723c6cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_conversion_rate_pd = spark.table(\"base_conversion_rate\").toPandas()\n",
    " \n",
    "pie, ax = plt.subplots(figsize=[20,9])\n",
    "labels = base_conversion_rate_pd['interaction_type']\n",
    "plt.pie(x=base_conversion_rate_pd['count'], autopct=\"%.1f%%\", explode=[0.05]*2, labels=labels, pctdistance=0.5)\n",
    "plt.title(\"Base Conversion Rate\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dbed87",
   "metadata": {},
   "source": [
    "### Conversions by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e42ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversions_by_date_pd = spark.table(\"conversions_by_date\").toPandas()\n",
    " \n",
    "plt.figure(figsize=(20,9))\n",
    "pt = sns.lineplot(x='date',y='count',data=conversions_by_date_pd)\n",
    " \n",
    "pt.tick_params(labelsize=20)\n",
    "pt.set_xlabel('Date')\n",
    "pt.set_ylabel('Number of Conversions')\n",
    "plt.title(\"Conversions by Date\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11adadb",
   "metadata": {},
   "source": [
    "### Attribution by model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db445c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TABLE attribution_by_model_type \n",
    "USING DELTA AS\n",
    "SELECT attribution_model, channel, round(attribution_percent * (\n",
    "    SELECT count(*) FROM gold_user_journey WHERE conversion = 1)) AS conversions_attributed\n",
    "FROM gold_attribution;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b19e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_by_model_type_pd = spark.table(\"attribution_by_model_type\").toPandas()\n",
    " \n",
    "pt = sns.catplot(x='channel',y='conversions_attributed',hue='attribution_model',data=attribution_by_model_type_pd, kind='bar', aspect=4, legend=True)\n",
    "pt.fig.set_figwidth(20)\n",
    "pt.fig.set_figheight(9)\n",
    " \n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel(\"Number of Conversions\")\n",
    "plt.xlabel(\"Channels\")\n",
    "plt.title(\"Channel Performance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0c78e7",
   "metadata": {},
   "source": [
    "### Cost per acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce752f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TABLE cpa_summary \n",
    "USING DELTA\n",
    "AS\n",
    "SELECT\n",
    "  spending.channel,\n",
    "  spending.dollar_spend,\n",
    "  attribution_count.attribution_model,\n",
    "  attribution_count.conversions_attributed,\n",
    "  round(spending.dollar_spend / attribution_count.conversions_attributed,2) AS CPA_in_Dollars\n",
    "FROM\n",
    "  (SELECT explode(channel_spend) AS (channel, spend),\n",
    "   round(total_spend_in_dollars * spend, 2) AS dollar_spend\n",
    "   FROM gold_ad_spend) AS spending\n",
    "JOIN\n",
    "  (SELECT attribution_model, channel, round(attribution_percent * (\n",
    "      SELECT count(*) FROM gold_user_journey WHERE conversion = 1)) AS conversions_attributed\n",
    "   FROM gold_attribution) AS attribution_count\n",
    "ON spending.channel = attribution_count.channel;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9276cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpa_summary_pd = spark.table(\"cpa_summary\").toPandas()\n",
    " \n",
    "pt = sns.catplot(x='channel', y='CPA_in_Dollars',hue='attribution_model',data=cpa_summary_pd, kind='bar', aspect=4, ci=None)\n",
    "plt.title(\"Cost of Acquisition by Channel\")\n",
    "pt.fig.set_figwidth(20)\n",
    "pt.fig.set_figheight(9)\n",
    " \n",
    "plt.tick_params(labelsize=15)\n",
    "plt.ylabel(\"CPA in $\")\n",
    "plt.xlabel(\"Channels\")\n",
    "plt.title(\"Channel Cost per Acquisition\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de448bd",
   "metadata": {},
   "source": [
    "### Budget Allocation Optimization.\n",
    "\n",
    "Now that we have assigned credit to our marketing channels using Markov Chains, we can take a data-driven approach for budget allocation.\n",
    "\n",
    "One KPI we can take a look at is Return on Ad Spend (ROAS).\n",
    "In the ecommerce world, ROAS is calculated as:\n",
    "- ROAS = Revenue from marketing/ Advertising spent\n",
    "\n",
    "In our example, instead of working with exact values, we will divide the % of conversion attributed to a channel by the % of total adspend allocated to that channel.\n",
    "\n",
    "- ROAS = CHANNEL CONVERSION WEIGHT / CHANNEL BUDGET WEIGHT\n",
    "- ROAS value > 1 signifies that the channel has been allocated less budget than warranted by its conversion rate.\n",
    "- ROAS value < 1 signifies that the channel has been allocated more budget than warranted by its conversion rate.\n",
    "- ROAS value = 1 signifies and optimized budget allocation.\n",
    "From ROAS, we can calculate the Proposed Budget for each channel\n",
    "\n",
    "Proposed budget = Current budget X ROAS\n",
    "To calculate ROAS we will join the following exploded_gold_ad_spend and usr_attribution Tables:\n",
    "\n",
    "**gold_attribution:** This table contains the calculated attribution % per channel based on different attribution models.\n",
    "exploded_gold_ad_spend: This table contains the current budget allocated per channel. The column pct_spend documents the % of the total budget that has been allocated to a given channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdcd98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM exploded_gold_ad_spend;\")\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4562c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"CREATE OR REPLACE TABLE spend_optimization_view \n",
    "USING DELTA\n",
    "AS\n",
    "SELECT\n",
    "  a.channel,\n",
    "  a.pct_spend,\n",
    "  b.attribution_percent,\n",
    "  b.attribution_percent / a.pct_spend as ROAS,\n",
    "  a.dollar_spend,\n",
    "  round(\n",
    "    (b.attribution_percent / a.pct_spend) * a.dollar_spend,\n",
    "    2\n",
    "  ) as proposed_dollar_spend\n",
    "FROM\n",
    "  exploded_gold_ad_spend a\n",
    "  JOIN gold_attribution b on a.channel = b.channel\n",
    "  and attribution_model = 'markov_chain';\n",
    "  \n",
    "CREATE\n",
    "OR REPLACE TABLE spend_optimization_final \n",
    "USING DELTA AS\n",
    "SELECT\n",
    "  channel,\n",
    "  'current_spending' AS spending,\n",
    "  dollar_spend as budget\n",
    " FROM exploded_gold_ad_spend\n",
    "UNION\n",
    "SELECT\n",
    "  channel,\n",
    "  'proposed_spending' AS spending,\n",
    "  proposed_dollar_spend as budget\n",
    "FROM\n",
    "  spend_optimization_view;\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788e8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "spend_optimization_final_pd = spark.table(\"spend_optimization_final\").toPandas()\n",
    " \n",
    "pt = sns.catplot(x='channel', y='budget', hue='spending', data=spend_optimization_final_pd, kind='bar', aspect=4, ci=None)\n",
    " \n",
    "plt.tick_params(labelsize=15)\n",
    "pt.fig.set_figwidth(20)\n",
    "pt.fig.set_figheight(9)\n",
    "plt.title(\"Spend Optimization per Channel\")\n",
    "plt.ylabel(\"Budget in $\")\n",
    "plt.xlabel(\"Channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affa0cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
